---
title: "p8105_hw3_hw2851"
output: github_document
---

```{r setup, include=FALSE}
library("tidyverse")
library(p8105.datasets)
data("instacart")
```

## Problem 1
```{r message=FALSE}
instacart
```

Let's first get an overview of the dataset. The instacart dataset has `r nrow(instacart)` rows. It contains `r length(instacart)` columns: `r colnames(instacart)`. Here is the first row of the dataset: `r head(instacart, n=1)`. Here is the last row of the dataset: `r tail(instacart, n=1)`. The table below shows some statistics of the key variables: the number of orders, the number of products, average number of products added to an order, the number of aisles and the number of departments.

```{r message=FALSE}
instacart %>%
  summarize(
    n_order_id = n_distinct(order_id),
    n_product_id = n_distinct(product_id),
    avg_add_to_cart_order = mean(add_to_cart_order),
    n_aisle_id = n_distinct(aisle),
    n_department = n_distinct(department_id),
  ) %>%
  knitr::kable()
```

How many aisles are there, and which aisles are the most items ordered from?

There are `r n_distinct(instacart$aisle)` aisles.  The aisles which the most orders are:
```{r message=FALSE}
instacart %>%
  count(aisle, name='n_orders') %>%
  filter(min_rank(desc(n_orders)) < 10) %>%
  arrange(desc(n_orders)) %>%
  knitr::kable()

```
 
```{r message=FALSE}
instacart_popular_aisles =
instacart %>%
  count(aisle, name='n_orders') %>%
  filter(n_orders > 10000)

ggplot(instacart_popular_aisles, aes(x = reorder(aisle, n_orders), y = n_orders)) +
  coord_flip() +
  geom_col(position = "dodge") +
  labs(
    title = "Number of orders for aisles with > 10k orders",
    x = "Aisle",
    y = "Number of orders"
  )
```
The plot above shows the number of orders for each aisle that have more than 10000 items ordered.
There are `r nrow(instacart_popular_aisles)` aisles with more than 10,000 orders. The aisles with the most numbers of orders are fresh vegetable and fresh fruits. They have more than 15k orders and excessively over other aisles.
```{r message=FALSE}
instacart %>%
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  count(aisle, product_name, name="n_orders") %>%
  group_by(aisle) %>%
  filter(rank(desc(n_orders)) <= 3.0) %>%
  arrange(aisle, n_orders)
```
```{r message = FALSE}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_order_hour_of_day = mean(order_hour_of_day, digit=2)) %>%
  pivot_wider(names_from=order_dow, values_from=mean_order_hour_of_day) %>%
  knitr::kable(digits = 1)
```
## Problem 2
```{r, include=FALSE}
library("tidyverse")
library(p8105.datasets)
data("brfss_smart2010")
```

```{r message=FALSE}
brfss_smart2010_clean =
brfss_smart2010 %>%
  # clean column names
  janitor::clean_names() %>%
  # only take "Overall Health" topic
  filter(topic == "Overall Health") %>%
  # make response a factor
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>%
  arrange(response)
brfss_smart2010_clean
```

```{r message=FALSE}
observed2002=
 brfss_smart2010_clean %>%
  filter(year == 2002) %>%
  group_by(locationabbr) %>%
  summarize(n_locations = n_distinct(locationdesc)) %>%
  filter(n_locations >= 7)
```
In 2002, there are 6 states that observed at 7 more locations including `r unique(observed2002$locationabbr)`
```{r message=FALSE}
observed2010=
 brfss_smart2010_clean %>%
  filter(year == 2010) %>%
  group_by(locationabbr) %>%
  summarize(n_locations = n_distinct(locationdesc)) %>%
  filter(n_locations >= 7)
```
In 2010, there are 14 states that observed at 7 more locations including `r unique(observed2010$locationabbr)`

```{r echo=FALSE} 
brfss_smart2010_clean %>%
  filter(response=="Excellent") %>%
  select(year, locationabbr, data_value) %>%
  group_by(year, locationabbr) %>%
  summarize(mean_data_value = mean(data_value)) %>%
  ggplot(aes(x = year, y = mean_data_value, color = locationabbr)) +
    geom_line()
```

```{r message=FALSE}
brfss_smart2010_clean %>%
  filter(locationabbr == "NY", year %in% c(2006, 2010)) %>%
  ggplot(aes(x = response, y = data_value)) +
  geom_violin(aes(fill = response), alpha = .5) +
  facet_grid(~year) +
  theme(legend.position = "bottom")
```

## Problem 3

```{r message=FALSE}
accel_data = read_csv('./data/accel_data.csv')%>%
  mutate(is_weekend = (day %in% c("Saturday", "Sunday"))) %>%
  pivot_longer(activity.1:activity.1440, names_to = "minute_of_day", names_prefix = "activity.", values_to = "activity_count")
  
```
There are 6 variables exist,including` colnames(accel_data)`, and total`r nrow(accel_data)` observations. Here is the first observation of the dataset: `r head(accel_data, n=1)`.
```{r message=FALSE}
accel_data %>%
  group_by(day_id) %>%
  summarize(total_activity = sum(activity_count)) %>%
  knitr::kable()
```

There is no any trends apparent was observed in this table. The activities looks stable from the begining to the end.There are two outlier in this dataset, they are data from day24 and day31. It should be excluded during analysis.
```{r message=FALSE}
accel_data %>%
  group_by(day_id, day) %>%
  summarize(total_activity = sum(activity_count)) %>%
  ggplot(aes(x = day_id, y = total_activity)) +
  geom_point(aes(color = day)) +
  geom_line(alpha = .5)
```

This person's activities shows weekly  periodic, for example, the total activities on every Tuesday approximately the same.This phenomenon is more obvious during weekday. The total activities on weekends fluctuate more,like the first Saturday is 631k, and the second Saturday drops to 422k. 